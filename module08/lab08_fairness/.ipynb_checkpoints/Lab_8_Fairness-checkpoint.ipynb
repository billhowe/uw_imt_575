{
 "cells": [
  {
   "cell_type": "raw",
   "id": "bd6cf2ec",
   "metadata": {},
   "source": [
    "Question 1: Using Microsoft's Fairlearn to build a more fair classifier for the Adult Dataset.\n",
    "\n",
    "Initially, we observe that the data contains about twice as many men than women with incomes over $50K. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a73c38a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      32650\n",
       "Female    16192\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reference method and code from here:\n",
    "#https://fairlearn.org/v0.7.0/quickstart.html\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "data = fetch_openml(data_id=1590, as_frame=True)\n",
    "X = pd.get_dummies(data.data)\n",
    "y_true = (data.target == '>50K') * 1\n",
    "sex = data.data['sex']\n",
    "sex.value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2bb76729",
   "metadata": {},
   "source": [
    "A decision tree classifier predicts whether an individual's income is >$50K or <=$50K with around 84% accuracy. However, the imbalances in the data lead to an imbalanced accuracy in predictions across our sensitive feature -- with 92% accuracy score for women and 80% accuracy for women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "523e4f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8443552680070431\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.metrics import MetricFrame\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(min_samples_leaf=10, max_depth=4)\n",
    "classifier.fit(X, y_true)\n",
    "\n",
    "y_pred = classifier.predict(X)\n",
    "\n",
    "gm = MetricFrame(metrics = accuracy_score, y_true = y_true, y_pred= y_pred, sensitive_features=sex)\n",
    "print(gm.overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "889e6f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "Female    0.925148\n",
      "Male      0.804288\n",
      "Name: accuracy_score, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(gm.by_group)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9108ed28",
   "metadata": {},
   "source": [
    "# Through examining a fairness metric such as selection rate, we learn that around 16% of individuals will have an income >$50K. However, men are over represented in this bracket. Men have a 21% chance of earning in this upper bracket, while women have only a 6% chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "652bfff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16385487899758405\n",
      "sex\n",
      "Female     0.06355\n",
      "Male      0.213599\n",
      "Name: selection_rate, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Examine selection rate across sexes\n",
    "from fairlearn.metrics import selection_rate\n",
    "\n",
    "sr = MetricFrame(metrics = selection_rate, y_true = y_true, y_pred= y_pred, sensitive_features=sex)\n",
    "\n",
    "print(sr.overall)\n",
    "print(sr.by_group)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c471bf4",
   "metadata": {},
   "source": [
    "We can use the Fairlearn tools to create a new model to mitigate for the disparity in this selection rate by modifying the Demographic Parity metric.\n",
    "\n",
    "The results of our more fair model demonstrate a 16-17% selection rate for individuals to earn in the upper >$50K bracket. However, this model creates more parity, with around a 15-17% chance that both men and women will fall within this high-income bracket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "71d7c1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16614798738790384\n",
      "sex\n",
      "Female    0.155262\n",
      "Male      0.171547\n",
      "Name: selection_rate, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Create new model to mitigate for disparate selection rate by modifying Demographic Parity metric\n",
    "\n",
    "from fairlearn.reductions import ExponentiatedGradient, DemographicParity\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "constraint = DemographicParity()\n",
    "classifier = DecisionTreeClassifier(min_samples_leaf=10, max_depth=4)\n",
    "mitigator = ExponentiatedGradient(classifier, constraint)\n",
    "\n",
    "mitigator.fit(X, y_true, sensitive_features=sex)\n",
    "\n",
    "y_pred_mitigated = mitigator.predict(X)\n",
    "\n",
    "sr_mitigated = MetricFrame(metrics = selection_rate, y_true=y_true, y_pred=y_pred_mitigated, sensitive_features=sex)\n",
    "\n",
    "print(sr_mitigated.overall)\n",
    "print(sr_mitigated.by_group)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf05f77c",
   "metadata": {},
   "source": [
    "Questions 2: We can use IBM's Fairness 360 library to accomplish a similar task for fairness in the Adult Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fa76ade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install aif360\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "from aif360.datasets import AdultDataset\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult\n",
    "from aif360.metrics import BinaryLabelDatasetMetric"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8eed8276",
   "metadata": {},
   "source": [
    "First, we split our data into training and test sets, and then compute the mean differences between men and women with regard to our binary label of income. We see that the mean differences are similar across both our training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3609e5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1930752110970722\n",
      "-0.19804754300152455\n"
     ]
    }
   ],
   "source": [
    "#Reference method and code from here:\n",
    "#https://github.com/Trusted-AI/AIF360/blob/master/examples/demo_adversarial_debiasing.ipynb\n",
    "\n",
    "#Compute fairness metric on original training data\n",
    "data_orig = load_preproc_data_adult()\n",
    "\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "data_orig_train, data_orig_test = data_orig.split([0.7], shuffle=True)\n",
    "\n",
    "metric_orig_train = BinaryLabelDatasetMetric(data_orig_train, \n",
    "                                      unprivileged_groups=unprivileged_groups,\n",
    "                                      privileged_groups=privileged_groups)\n",
    "\n",
    "metric_orig_test = BinaryLabelDatasetMetric(data_orig_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "#Mean differences between 'male' and 'female' groups\n",
    "print(metric_orig_train.mean_difference())\n",
    "print(metric_orig_test.mean_difference())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc039a05",
   "metadata": {},
   "source": [
    "We then apply scaling to both the training and test sets as part of preprocessing. We confirm that the processing does not affect the mean differences as calculated above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1e68d17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1930752110970722\n",
      "-0.19804754300152455\n"
     ]
    }
   ],
   "source": [
    "#Apply scaling to dataset\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "\n",
    "min_max_scaler = MaxAbsScaler()\n",
    "data_orig_train.features = min_max_scaler.fit_transform(data_orig_train.features)\n",
    "data_orig_test.features = min_max_scaler.transform(data_orig_test.features)\n",
    "\n",
    "#Scale train\n",
    "metric_scaled_train = BinaryLabelDatasetMetric(data_orig_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "\n",
    "#Scale test\n",
    "metric_scaled_test = BinaryLabelDatasetMetric(data_orig_test, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(metric_scaled_train.mean_difference())\n",
    "print(metric_scaled_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3050020",
   "metadata": {},
   "source": [
    "We then fit the training data with a non-debiased model using the AIF360 adversarial debiasing classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "15207940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.692007\n",
      "epoch 0; iter: 200; batch classifier loss: 0.402107\n",
      "epoch 1; iter: 0; batch classifier loss: 0.437729\n",
      "epoch 1; iter: 200; batch classifier loss: 0.504335\n",
      "epoch 2; iter: 0; batch classifier loss: 0.394550\n",
      "epoch 2; iter: 200; batch classifier loss: 0.488978\n",
      "epoch 3; iter: 0; batch classifier loss: 0.467837\n",
      "epoch 3; iter: 200; batch classifier loss: 0.393646\n",
      "epoch 4; iter: 0; batch classifier loss: 0.406567\n",
      "epoch 4; iter: 200; batch classifier loss: 0.381459\n",
      "epoch 5; iter: 0; batch classifier loss: 0.385749\n",
      "epoch 5; iter: 200; batch classifier loss: 0.428927\n",
      "epoch 6; iter: 0; batch classifier loss: 0.455799\n",
      "epoch 6; iter: 200; batch classifier loss: 0.411776\n",
      "epoch 7; iter: 0; batch classifier loss: 0.314866\n",
      "epoch 7; iter: 200; batch classifier loss: 0.436166\n",
      "epoch 8; iter: 0; batch classifier loss: 0.430930\n",
      "epoch 8; iter: 200; batch classifier loss: 0.401677\n",
      "epoch 9; iter: 0; batch classifier loss: 0.488311\n",
      "epoch 9; iter: 200; batch classifier loss: 0.433479\n",
      "epoch 10; iter: 0; batch classifier loss: 0.401633\n",
      "epoch 10; iter: 200; batch classifier loss: 0.415212\n",
      "epoch 11; iter: 0; batch classifier loss: 0.384736\n",
      "epoch 11; iter: 200; batch classifier loss: 0.400926\n",
      "epoch 12; iter: 0; batch classifier loss: 0.428928\n",
      "epoch 12; iter: 200; batch classifier loss: 0.364453\n",
      "epoch 13; iter: 0; batch classifier loss: 0.466903\n",
      "epoch 13; iter: 200; batch classifier loss: 0.396736\n",
      "epoch 14; iter: 0; batch classifier loss: 0.387231\n",
      "epoch 14; iter: 200; batch classifier loss: 0.379546\n",
      "epoch 15; iter: 0; batch classifier loss: 0.377797\n",
      "epoch 15; iter: 200; batch classifier loss: 0.459949\n",
      "epoch 16; iter: 0; batch classifier loss: 0.405540\n",
      "epoch 16; iter: 200; batch classifier loss: 0.406011\n",
      "epoch 17; iter: 0; batch classifier loss: 0.303668\n",
      "epoch 17; iter: 200; batch classifier loss: 0.395922\n",
      "epoch 18; iter: 0; batch classifier loss: 0.414053\n",
      "epoch 18; iter: 200; batch classifier loss: 0.458730\n",
      "epoch 19; iter: 0; batch classifier loss: 0.399212\n",
      "epoch 19; iter: 200; batch classifier loss: 0.481229\n",
      "epoch 20; iter: 0; batch classifier loss: 0.405513\n",
      "epoch 20; iter: 200; batch classifier loss: 0.458068\n",
      "epoch 21; iter: 0; batch classifier loss: 0.398734\n",
      "epoch 21; iter: 200; batch classifier loss: 0.329397\n",
      "epoch 22; iter: 0; batch classifier loss: 0.431164\n",
      "epoch 22; iter: 200; batch classifier loss: 0.377024\n",
      "epoch 23; iter: 0; batch classifier loss: 0.393747\n",
      "epoch 23; iter: 200; batch classifier loss: 0.457169\n",
      "epoch 24; iter: 0; batch classifier loss: 0.380524\n",
      "epoch 24; iter: 200; batch classifier loss: 0.383436\n",
      "epoch 25; iter: 0; batch classifier loss: 0.439645\n",
      "epoch 25; iter: 200; batch classifier loss: 0.445211\n",
      "epoch 26; iter: 0; batch classifier loss: 0.419946\n",
      "epoch 26; iter: 200; batch classifier loss: 0.376784\n",
      "epoch 27; iter: 0; batch classifier loss: 0.429152\n",
      "epoch 27; iter: 200; batch classifier loss: 0.366975\n",
      "epoch 28; iter: 0; batch classifier loss: 0.452733\n",
      "epoch 28; iter: 200; batch classifier loss: 0.410123\n",
      "epoch 29; iter: 0; batch classifier loss: 0.404088\n",
      "epoch 29; iter: 200; batch classifier loss: 0.405635\n",
      "epoch 30; iter: 0; batch classifier loss: 0.438385\n",
      "epoch 30; iter: 200; batch classifier loss: 0.335544\n",
      "epoch 31; iter: 0; batch classifier loss: 0.460789\n",
      "epoch 31; iter: 200; batch classifier loss: 0.349052\n",
      "epoch 32; iter: 0; batch classifier loss: 0.364024\n",
      "epoch 32; iter: 200; batch classifier loss: 0.369136\n",
      "epoch 33; iter: 0; batch classifier loss: 0.434996\n",
      "epoch 33; iter: 200; batch classifier loss: 0.338463\n",
      "epoch 34; iter: 0; batch classifier loss: 0.513441\n",
      "epoch 34; iter: 200; batch classifier loss: 0.514083\n",
      "epoch 35; iter: 0; batch classifier loss: 0.423819\n",
      "epoch 35; iter: 200; batch classifier loss: 0.412511\n",
      "epoch 36; iter: 0; batch classifier loss: 0.391708\n",
      "epoch 36; iter: 200; batch classifier loss: 0.491084\n",
      "epoch 37; iter: 0; batch classifier loss: 0.359645\n",
      "epoch 37; iter: 200; batch classifier loss: 0.398946\n",
      "epoch 38; iter: 0; batch classifier loss: 0.469651\n",
      "epoch 38; iter: 200; batch classifier loss: 0.492531\n",
      "epoch 39; iter: 0; batch classifier loss: 0.465807\n",
      "epoch 39; iter: 200; batch classifier loss: 0.468319\n",
      "epoch 40; iter: 0; batch classifier loss: 0.527578\n",
      "epoch 40; iter: 200; batch classifier loss: 0.464881\n",
      "epoch 41; iter: 0; batch classifier loss: 0.423217\n",
      "epoch 41; iter: 200; batch classifier loss: 0.396996\n",
      "epoch 42; iter: 0; batch classifier loss: 0.430948\n",
      "epoch 42; iter: 200; batch classifier loss: 0.318878\n",
      "epoch 43; iter: 0; batch classifier loss: 0.344889\n",
      "epoch 43; iter: 200; batch classifier loss: 0.424319\n",
      "epoch 44; iter: 0; batch classifier loss: 0.381978\n",
      "epoch 44; iter: 200; batch classifier loss: 0.442283\n",
      "epoch 45; iter: 0; batch classifier loss: 0.441619\n",
      "epoch 45; iter: 200; batch classifier loss: 0.375074\n",
      "epoch 46; iter: 0; batch classifier loss: 0.499723\n",
      "epoch 46; iter: 200; batch classifier loss: 0.484272\n",
      "epoch 47; iter: 0; batch classifier loss: 0.422684\n",
      "epoch 47; iter: 200; batch classifier loss: 0.504582\n",
      "epoch 48; iter: 0; batch classifier loss: 0.393714\n",
      "epoch 48; iter: 200; batch classifier loss: 0.394230\n",
      "epoch 49; iter: 0; batch classifier loss: 0.393788\n",
      "epoch 49; iter: 200; batch classifier loss: 0.428729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7fa6c389d3a0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Learn adversarial debiasing classifier without debiasing \n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.reset_default_graph() \n",
    "tf.disable_eager_execution()\n",
    "\n",
    "biased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=False, \n",
    "                           sess=tf.Session())\n",
    "\n",
    "biased_model.fit(data_orig_train)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bdb23311",
   "metadata": {},
   "source": [
    "We can then apply this biased model to make predictions to be compared against our test data. The model reports a mean difference of 0.22 between men and women. This disparity is greater than the 0.19 mean difference in our raw data, demonstrating how a model trained on biased raw data can serve to exacerbate inequity. \n",
    "\n",
    "The biased model reports an accuracy score of 80% when confronting our test data. We also note a very unfair disparate impact ratio of 0. Bringing this value to 0.8 or higher would avoid this disparate impact violation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e2f14d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.20557244174265452\n",
      "0.8042039172865625\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "#Apply biased model to test data\n",
    "data_nodebiasing_test = biased_model.predict(data_orig_test)\n",
    "\n",
    "#Report mean differences between 'male' and 'female' groups\n",
    "metric_nodebiasing_test = BinaryLabelDatasetMetric(data_nodebiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "\n",
    "print(metric_nodebiasing_test.mean_difference())\n",
    "\n",
    "#Report classification accuracy\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(data_orig_test, \n",
    "                                                 data_nodebiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "\n",
    "print(classified_metric_nodebiasing_test.accuracy())\n",
    "\n",
    "#Report disparate impact ratio\n",
    "print(classified_metric_nodebiasing_test.disparate_impact())\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eafcd67d",
   "metadata": {},
   "source": [
    "We then fit the training data with another model, allowing for debiasing. This should result in a more fair model with more equitable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "88dc2dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.685663; batch adversarial loss: 0.866392\n",
      "epoch 0; iter: 200; batch classifier loss: 0.829415; batch adversarial loss: 0.957977\n",
      "epoch 1; iter: 0; batch classifier loss: 0.948465; batch adversarial loss: 0.914112\n",
      "epoch 1; iter: 200; batch classifier loss: 0.661319; batch adversarial loss: 0.757911\n",
      "epoch 2; iter: 0; batch classifier loss: 0.510904; batch adversarial loss: 0.698530\n",
      "epoch 2; iter: 200; batch classifier loss: 0.383084; batch adversarial loss: 0.654228\n",
      "epoch 3; iter: 0; batch classifier loss: 0.353087; batch adversarial loss: 0.658804\n",
      "epoch 3; iter: 200; batch classifier loss: 0.416485; batch adversarial loss: 0.649679\n",
      "epoch 4; iter: 0; batch classifier loss: 0.444525; batch adversarial loss: 0.614053\n",
      "epoch 4; iter: 200; batch classifier loss: 0.472028; batch adversarial loss: 0.676581\n",
      "epoch 5; iter: 0; batch classifier loss: 0.500998; batch adversarial loss: 0.633211\n",
      "epoch 5; iter: 200; batch classifier loss: 0.458376; batch adversarial loss: 0.606889\n",
      "epoch 6; iter: 0; batch classifier loss: 0.370535; batch adversarial loss: 0.616346\n",
      "epoch 6; iter: 200; batch classifier loss: 0.527565; batch adversarial loss: 0.603514\n",
      "epoch 7; iter: 0; batch classifier loss: 0.429683; batch adversarial loss: 0.616737\n",
      "epoch 7; iter: 200; batch classifier loss: 0.462236; batch adversarial loss: 0.620302\n",
      "epoch 8; iter: 0; batch classifier loss: 0.500681; batch adversarial loss: 0.645257\n",
      "epoch 8; iter: 200; batch classifier loss: 0.449347; batch adversarial loss: 0.561517\n",
      "epoch 9; iter: 0; batch classifier loss: 0.343782; batch adversarial loss: 0.607865\n",
      "epoch 9; iter: 200; batch classifier loss: 0.386621; batch adversarial loss: 0.560818\n",
      "epoch 10; iter: 0; batch classifier loss: 0.464457; batch adversarial loss: 0.617118\n",
      "epoch 10; iter: 200; batch classifier loss: 0.470352; batch adversarial loss: 0.619108\n",
      "epoch 11; iter: 0; batch classifier loss: 0.411231; batch adversarial loss: 0.705213\n",
      "epoch 11; iter: 200; batch classifier loss: 0.424621; batch adversarial loss: 0.615561\n",
      "epoch 12; iter: 0; batch classifier loss: 0.433711; batch adversarial loss: 0.655591\n",
      "epoch 12; iter: 200; batch classifier loss: 0.501063; batch adversarial loss: 0.635122\n",
      "epoch 13; iter: 0; batch classifier loss: 0.516226; batch adversarial loss: 0.665943\n",
      "epoch 13; iter: 200; batch classifier loss: 0.544099; batch adversarial loss: 0.633990\n",
      "epoch 14; iter: 0; batch classifier loss: 0.431760; batch adversarial loss: 0.642192\n",
      "epoch 14; iter: 200; batch classifier loss: 0.444371; batch adversarial loss: 0.619304\n",
      "epoch 15; iter: 0; batch classifier loss: 0.402111; batch adversarial loss: 0.649541\n",
      "epoch 15; iter: 200; batch classifier loss: 0.368401; batch adversarial loss: 0.621162\n",
      "epoch 16; iter: 0; batch classifier loss: 0.402411; batch adversarial loss: 0.605115\n",
      "epoch 16; iter: 200; batch classifier loss: 0.333361; batch adversarial loss: 0.638978\n",
      "epoch 17; iter: 0; batch classifier loss: 0.414880; batch adversarial loss: 0.647650\n",
      "epoch 17; iter: 200; batch classifier loss: 0.360511; batch adversarial loss: 0.609638\n",
      "epoch 18; iter: 0; batch classifier loss: 0.409168; batch adversarial loss: 0.604560\n",
      "epoch 18; iter: 200; batch classifier loss: 0.518626; batch adversarial loss: 0.652262\n",
      "epoch 19; iter: 0; batch classifier loss: 0.471150; batch adversarial loss: 0.636419\n",
      "epoch 19; iter: 200; batch classifier loss: 0.413167; batch adversarial loss: 0.677628\n",
      "epoch 20; iter: 0; batch classifier loss: 0.407654; batch adversarial loss: 0.617524\n",
      "epoch 20; iter: 200; batch classifier loss: 0.435330; batch adversarial loss: 0.633945\n",
      "epoch 21; iter: 0; batch classifier loss: 0.409170; batch adversarial loss: 0.616557\n",
      "epoch 21; iter: 200; batch classifier loss: 0.452480; batch adversarial loss: 0.614563\n",
      "epoch 22; iter: 0; batch classifier loss: 0.451312; batch adversarial loss: 0.584486\n",
      "epoch 22; iter: 200; batch classifier loss: 0.363107; batch adversarial loss: 0.621937\n",
      "epoch 23; iter: 0; batch classifier loss: 0.420341; batch adversarial loss: 0.624325\n",
      "epoch 23; iter: 200; batch classifier loss: 0.455129; batch adversarial loss: 0.669676\n",
      "epoch 24; iter: 0; batch classifier loss: 0.512174; batch adversarial loss: 0.565825\n",
      "epoch 24; iter: 200; batch classifier loss: 0.447606; batch adversarial loss: 0.594498\n",
      "epoch 25; iter: 0; batch classifier loss: 0.442613; batch adversarial loss: 0.575627\n",
      "epoch 25; iter: 200; batch classifier loss: 0.425224; batch adversarial loss: 0.585117\n",
      "epoch 26; iter: 0; batch classifier loss: 0.364210; batch adversarial loss: 0.628184\n",
      "epoch 26; iter: 200; batch classifier loss: 0.458869; batch adversarial loss: 0.585415\n",
      "epoch 27; iter: 0; batch classifier loss: 0.382342; batch adversarial loss: 0.592436\n",
      "epoch 27; iter: 200; batch classifier loss: 0.423086; batch adversarial loss: 0.647344\n",
      "epoch 28; iter: 0; batch classifier loss: 0.496842; batch adversarial loss: 0.589018\n",
      "epoch 28; iter: 200; batch classifier loss: 0.443242; batch adversarial loss: 0.618704\n",
      "epoch 29; iter: 0; batch classifier loss: 0.492237; batch adversarial loss: 0.592667\n",
      "epoch 29; iter: 200; batch classifier loss: 0.433226; batch adversarial loss: 0.607434\n",
      "epoch 30; iter: 0; batch classifier loss: 0.407520; batch adversarial loss: 0.638074\n",
      "epoch 30; iter: 200; batch classifier loss: 0.496096; batch adversarial loss: 0.624634\n",
      "epoch 31; iter: 0; batch classifier loss: 0.378176; batch adversarial loss: 0.624284\n",
      "epoch 31; iter: 200; batch classifier loss: 0.445916; batch adversarial loss: 0.599609\n",
      "epoch 32; iter: 0; batch classifier loss: 0.412533; batch adversarial loss: 0.583030\n",
      "epoch 32; iter: 200; batch classifier loss: 0.432020; batch adversarial loss: 0.585705\n",
      "epoch 33; iter: 0; batch classifier loss: 0.412551; batch adversarial loss: 0.642222\n",
      "epoch 33; iter: 200; batch classifier loss: 0.403330; batch adversarial loss: 0.624537\n",
      "epoch 34; iter: 0; batch classifier loss: 0.399968; batch adversarial loss: 0.652654\n",
      "epoch 34; iter: 200; batch classifier loss: 0.424872; batch adversarial loss: 0.579494\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458806; batch adversarial loss: 0.583386\n",
      "epoch 35; iter: 200; batch classifier loss: 0.506482; batch adversarial loss: 0.576741\n",
      "epoch 36; iter: 0; batch classifier loss: 0.483355; batch adversarial loss: 0.589551\n",
      "epoch 36; iter: 200; batch classifier loss: 0.374940; batch adversarial loss: 0.540536\n",
      "epoch 37; iter: 0; batch classifier loss: 0.386293; batch adversarial loss: 0.600495\n",
      "epoch 37; iter: 200; batch classifier loss: 0.420285; batch adversarial loss: 0.597748\n",
      "epoch 38; iter: 0; batch classifier loss: 0.452663; batch adversarial loss: 0.644690\n",
      "epoch 38; iter: 200; batch classifier loss: 0.469852; batch adversarial loss: 0.703601\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431373; batch adversarial loss: 0.602268\n",
      "epoch 39; iter: 200; batch classifier loss: 0.438715; batch adversarial loss: 0.626031\n",
      "epoch 40; iter: 0; batch classifier loss: 0.440885; batch adversarial loss: 0.585576\n",
      "epoch 40; iter: 200; batch classifier loss: 0.431025; batch adversarial loss: 0.610393\n",
      "epoch 41; iter: 0; batch classifier loss: 0.447368; batch adversarial loss: 0.618341\n",
      "epoch 41; iter: 200; batch classifier loss: 0.364264; batch adversarial loss: 0.607802\n",
      "epoch 42; iter: 0; batch classifier loss: 0.450193; batch adversarial loss: 0.599725\n",
      "epoch 42; iter: 200; batch classifier loss: 0.436703; batch adversarial loss: 0.549484\n",
      "epoch 43; iter: 0; batch classifier loss: 0.422128; batch adversarial loss: 0.648330\n",
      "epoch 43; iter: 200; batch classifier loss: 0.492264; batch adversarial loss: 0.638208\n",
      "epoch 44; iter: 0; batch classifier loss: 0.489698; batch adversarial loss: 0.604889\n",
      "epoch 44; iter: 200; batch classifier loss: 0.464972; batch adversarial loss: 0.527327\n",
      "epoch 45; iter: 0; batch classifier loss: 0.470247; batch adversarial loss: 0.538367\n",
      "epoch 45; iter: 200; batch classifier loss: 0.467819; batch adversarial loss: 0.597502\n",
      "epoch 46; iter: 0; batch classifier loss: 0.405761; batch adversarial loss: 0.597955\n",
      "epoch 46; iter: 200; batch classifier loss: 0.437702; batch adversarial loss: 0.599687\n",
      "epoch 47; iter: 0; batch classifier loss: 0.424657; batch adversarial loss: 0.597499\n",
      "epoch 47; iter: 200; batch classifier loss: 0.359275; batch adversarial loss: 0.629186\n",
      "epoch 48; iter: 0; batch classifier loss: 0.481288; batch adversarial loss: 0.661231\n",
      "epoch 48; iter: 200; batch classifier loss: 0.467952; batch adversarial loss: 0.640572\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432672; batch adversarial loss: 0.664035\n",
      "epoch 49; iter: 200; batch classifier loss: 0.400260; batch adversarial loss: 0.565386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7fa6c2485c10>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conduct fairness metric analysis after fitting model with debiasing option\n",
    "tf.Session().close()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='debiased_classifier',\n",
    "                          debias=True, \n",
    "                           sess=tf.Session())\n",
    "\n",
    "debiased_model.fit(data_orig_train)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b048afa9",
   "metadata": {},
   "source": [
    "This model returns more fair results. The mean difference between men and women is reduced from 0.19 in our raw data and 0.22 under our biased model to 0.08 in our fairer model. \n",
    "\n",
    "Furthermore, our overall classification accuracy remains relatively the same at 79%. However, we observe a jump in the disparity impact ratio from very unfair at 0 to somewhat more fair at 0.6. By the disparate impact metric, this model would still be considered a violation of the four-fifths rule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c132be76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.08326598276020208\n",
      "0.7913737801132874\n",
      "0.588258892864131\n"
     ]
    }
   ],
   "source": [
    "#Apply debiased model to test data\n",
    "data_debiased_test = debiased_model.predict(data_orig_test)\n",
    "\n",
    "#Report debiased mean differences between 'male' and 'female' groups\n",
    "metric_debiased_test = BinaryLabelDatasetMetric(data_debiased_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(metric_debiased_test.mean_difference())\n",
    "\n",
    "#Report debiased classification accuracy\n",
    "classified_metric_debiased_test = ClassificationMetric(data_orig_test, \n",
    "                                                 data_debiased_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "\n",
    "print(classified_metric_debiased_test.accuracy())\n",
    "\n",
    "#Report disparate impact ratio\n",
    "print(classified_metric_debiased_test.disparate_impact())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7421ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
